{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating fundamental dataset.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWGByFidTsUP",
        "colab_type": "text"
      },
      "source": [
        "Installing the SimFin  and yFinance API and importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q_R4gHCDXi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install simfin\n",
        "!pip install yfinance\n",
        "import simfin as sf\n",
        "from simfin.names import *\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "np.load.__defaults__=(None, True, True, 'ASCII')\n",
        "sf.set_api_key('free')\n",
        "import yfinance as yf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSyK7omdT0xN",
        "colab_type": "text"
      },
      "source": [
        "Loading the datasets which will be transformed and printing out their shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ3O0vUnDXdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sf.set_data_dir('/content/drive/My Drive/Data Sets')\n",
        "\n",
        "cashflow_df = sf.load_cashflow(variant='quarterly', market='us')\n",
        "balance_Df = sf.load_balance(variant= 'quarterly', market = 'us')\n",
        "income_df = sf.load_income(variant='quarterly', market='us')\n",
        "\n",
        "print(cashflow_df.shape)\n",
        "print(balance_Df.shape)\n",
        "print(income_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8z_x46aUmYN",
        "colab_type": "text"
      },
      "source": [
        "Removing duplicate columns and combining the three datasets into a single one. The dataset is can be saved as a .csv file for easy accesss. Uncomment the code for saving and loading the ready dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxQflzKYyslR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cashflow_df = cashflow_df.drop(columns=['SimFinId', 'Currency','Fiscal Year', 'Fiscal Period', 'Publish Date', 'Shares (Basic)', 'Shares (Diluted)', 'Depreciation & Amortization'])\n",
        "balance_Df = balance_Df.drop(columns=['SimFinId', 'Currency','Fiscal Year', 'Fiscal Period', 'Publish Date', 'Shares (Basic)', 'Shares (Diluted)'])\n",
        "income_df = income_df.join(cashflow_df)\n",
        "big_data = income_df.join(balance_Df)\n",
        "#big_data.reset_index(inplace=True)\n",
        "#big_data.to_csv('/content/drive/My Drive/Data Sets/combined_fundamental.csv')\n",
        "#big_data = pd.read_csv('/content/drive/My Drive/Data Sets/combined_fundamental.csv')\n",
        "#big_data.set_index(['Ticker', 'Report Date'], inplace=True)\n",
        "#big_data.drop(columns='Unnamed: 0', inplace=True)\n",
        "big_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sRSQMrDgqqk",
        "colab_type": "text"
      },
      "source": [
        "The yFinance API is used to get the daily pricing data of the SP 500 index and the companies in the fundamental data set. The dates of the reports are cross-referenced with the price for the same day of both the index and the company. We check if the report release date was during the weekend or on a holiday and attempt to get the last available price if they are. If we are unable to find a price we move on to the next company. Takes approximately 30 minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL2DIuttEXZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get price data for the SP 500\n",
        "ticker_index = yf.Ticker(\"^GSPC\")\n",
        "history_index = ticker_index.history(period='max', interval='1d')\n",
        "history_index.drop(columns= ['Dividends', 'Stock Splits'])\n",
        "time.sleep(1)\n",
        "\n",
        "ticker = \"\"\n",
        "\n",
        "# Iterate through all companies\n",
        "for index, row in big_data.iterrows():\n",
        "  try:\n",
        "    date = datetime.strptime(str(index[1]), '%Y-%m-%d').date()\n",
        "  except:\n",
        "    date = datetime.strptime(str(index[1]), '%Y-%m-%d %H:%M:%S').date()\n",
        "\n",
        "  # Check if we have reached a different company and update price data accordingly\n",
        "  if ticker != str(index[0]):\n",
        "    print(\"Old ticker\", ticker)\n",
        "    ticker = str(index[0])\n",
        "    print(\"New ticker\", ticker)\n",
        "    yh_tick = yf.Ticker(ticker)\n",
        "    history_stock = yh_tick.history(period='max', interval = '1d')\n",
        "    if history_stock.empty:\n",
        "      time.sleep(1)\n",
        "      continue\n",
        "    time.sleep(1)\n",
        "\n",
        "  # Check if the report has been released on Saturday and attempt to find price data\n",
        "  if date.weekday() == 5:\n",
        "    try:\n",
        "      big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=1)), 'Close']\n",
        "      big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=1)), 'Close']\n",
        "    except:\n",
        "      print(\"Saturday - 2\")\n",
        "      try:\n",
        "        big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=2)), 'Close']\n",
        "        big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=2)), 'Close']\n",
        "      except:\n",
        "        print('Saturday - 4')\n",
        "        try:\n",
        "          big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=4)), 'Close']\n",
        "          big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=4)), 'Close']\n",
        "        except:\n",
        "          print(\"Skipped\")\n",
        "          continue\n",
        "  \n",
        "  # Check if the report has been released on Sunday and attempt to find price data \n",
        "  elif date.weekday() == 6:\n",
        "    try:\n",
        "      big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=2)), 'Close']\n",
        "      big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=2)), 'Close']\n",
        "    except:\n",
        "      print(\"Sunday - 2\")\n",
        "      try:\n",
        "        big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=3)), 'Close']\n",
        "        big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=3)), 'Close']\n",
        "      except:\n",
        "        print('Sunday - 4')\n",
        "        try:\n",
        "          big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=4)), 'Close']\n",
        "          big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=4)), 'Close']\n",
        "        except:\n",
        "          print(\"Skipped\")\n",
        "          continue\n",
        "\n",
        "  # If the report has been released on a weekday attempt to get the price.\n",
        "  else:\n",
        "    try:\n",
        "      big_data.at[(index), 'Stock Price'] = history_stock.at[str(date), 'Close']\n",
        "      big_data.at[(index), 'Index Price'] = history_index.at[str(date), 'Close']\n",
        "    except:\n",
        "      print('Work day - 2')\n",
        "      try:\n",
        "        big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=2)), 'Close']\n",
        "        big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=2)), 'Close']\n",
        "      except:\n",
        "        print('Work day - 4')\n",
        "        try:\n",
        "          big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=4)), 'Close']\n",
        "          big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=4)), 'Close']\n",
        "        except:\n",
        "          print('Work day - 6')\n",
        "          try:\n",
        "            big_data.at[(index), 'Stock Price'] = history_stock.at[str(date - timedelta(days=6)), 'Close']\n",
        "            big_data.at[(index), 'Index Price'] = history_index.at[str(date - timedelta(days=6)), 'Close']\n",
        "          except:\n",
        "            print(\"Skipped\")\n",
        "            continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MRb_g1zigNK",
        "colab_type": "text"
      },
      "source": [
        "The companies for which we are unable to find price data are removed from the dataset. The dataset is saved to csv for faster and easier access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lam6u7GYkqUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(big_data.shape)\n",
        "big_data = big_data.drop(big_data[big_data['Stock Price'].isna()].index)\n",
        "print(big_data.shape)\n",
        "big_data.to_csv(\"/content/drive/My Drive/Data Sets/fundamental_dataset_no_na.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgAPo1KHip9C",
        "colab_type": "text"
      },
      "source": [
        "Creates a list of all companies left in the data set and sets Ticker and Report date as an index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3CKPkqQcDeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_data.reset_index(inplace=True)\n",
        "big_data.set_index('Ticker', inplace=True)\n",
        "company_index = big_data.index.unique()\n",
        "print(company_index)\n",
        "big_data.reset_index(inplace=True)\n",
        "big_data.set_index(['Ticker', 'Report Date'], inplace=True)\n",
        "big_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6engjtvhlrgL",
        "colab_type": "text"
      },
      "source": [
        "Calculates the percent change of the stock and market prices since the first report we have available for the current date. Calculates the difference in percentages and labels as an outperformer if the company's price has increased more than the one of the index. Otherwise, it labels the company as an underperfomer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhAY73jcAzyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for company in company_index:\n",
        "  \n",
        "  reports = big_data.loc[company].index\n",
        "  starting_index_value = big_data.at[(company, reports[0]), 'Index Price']\n",
        "  starting_stock_value = big_data.at[(company, reports[0]), 'Stock Price']\n",
        "\n",
        "  for report in reports:\n",
        "    current_index_value = big_data.at[(company, report), 'Index Price']\n",
        "    current_stock_value = big_data.at[(company, report), 'Stock Price']\n",
        "\n",
        "    stock_percent_difference = ((current_stock_value-starting_stock_value)/starting_stock_value)* 100.0\n",
        "    index_percent_difference = ((current_index_value-starting_index_value)/starting_index_value)* 100.0\n",
        "\n",
        "    big_data.at[(company, report), 'Stock Percent Difference'] = stock_percent_difference\n",
        "    big_data.at[(company, report), 'Index Percent Difference'] = index_percent_difference\n",
        "\n",
        "    price_percent_difference = stock_percent_difference - index_percent_difference\n",
        "\n",
        "    if price_percent_difference > 0:\n",
        "      big_data.at[(company, report), 'Label'] = 1\n",
        "    else:\n",
        "      big_data.at[(company, report), 'Label'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVnJZZNKmh5s",
        "colab_type": "text"
      },
      "source": [
        "Removes an unnecessary column and saves the labelled data set as a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IglIa3AOIHHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_data.drop(columns=['SimFinId'], inplace=True)\n",
        "big_data.to_csv('/content/drive/My Drive/Data Sets/labelled_fundamental_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQn6HCIfm49Z",
        "colab_type": "text"
      },
      "source": [
        "Used to find the oldest and newest report in the labelled data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCCQWlX36WA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime as dt\n",
        "big_data = pd.read_csv('/content/drive/My Drive/Data Sets/labelled_fundamental_data.csv')\n",
        "print(max(pd.to_datetime(big_data['Report Date'], format='%Y-%m-%d').dt.date))\n",
        "print(min(pd.to_datetime(big_data['Report Date'], format='%Y-%m-%d').dt.date))\n",
        "big_data"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}